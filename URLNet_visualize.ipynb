{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_util import *\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load URLNet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_seq_len = 200\n",
    "char_seq_len = 200\n",
    "ngram_seq_len = 20\n",
    "chars_dict_len = 1406 \n",
    "word_dict_len = 10507\n",
    "ngram_dict_len = 1406\n",
    "reg_lambda = 0 \n",
    "emb_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of char_input:  (None, 200)\n",
      "char-Embedding:  (None, 200, 32)\n",
      "char-convOutput :  (None, 198, 256)\n",
      "char - maxPool shape:  (None, 1, 256)\n",
      "char-convOutput :  (None, 197, 256)\n",
      "char - maxPool shape:  (None, 1, 256)\n",
      "char-convOutput :  (None, 196, 256)\n",
      "char - maxPool shape:  (None, 1, 256)\n",
      "char-convOutput :  (None, 195, 256)\n",
      "char - maxPool shape:  (None, 1, 256)\n",
      "4 filter output pooled:  (None, 4, 256)\n",
      "word-embedding:  (None, 200, 32)\n",
      "word_flat shape:  (None, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6294526e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = getModel(word_seq_len, char_seq_len, ngram_seq_len, chars_dict_len, word_dict_len, ngram_dict_len, reg_lambda, emb_dim)\n",
    "model.load_weights(\"/home/youngjai/sampleData/ailab/workspace/youngjai_kwon/pml-data/model/2020-11-09/small_70k\")\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data 가져오기 \n",
    "\n",
    "* 각각의 데이터 경로에 저장되어 있는 TFRecord 형태의 데이터 가져오기     \n",
    "* tf.DataSet API 로 읽어오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_dir = \"/home/youngjai/sampleData/ailab/workspace/youngjai_kwon/pml-data/engineered-data/totalSet/2020-11-09/small_splitted/train.tfrecord/part-r-\"\n",
    "train_data_dir = [train_base_dir+str(idx).zfill(5) for idx in range(5)]\n",
    "\n",
    "val_base_dir =  \"/home/youngjai/sampleData/ailab/workspace/youngjai_kwon/pml-data/engineered-data/totalSet/2020-11-09/small_splitted/test.tfrecord/part-r-\"\n",
    "val_data_dir = [val_base_dir+str(idx).zfill(5) for idx in range(5)]\n",
    "\n",
    "oop_base_dir = \"/home/youngjai/sampleData/ailab/workspace/youngjai_kwon/pml-data/engineered-data/totalSet/2020-11-09/small_oop/tfrecords\"\n",
    "oop_data_dir = [oop_base_dir + str(idx).zfill(5) for idx in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = input_fn(train_data_dir, word_seq_len, char_seq_len, ngram_seq_len, 10000, 256)\n",
    "val_dataset = input_fn(val_data_dir, word_seq_len, char_seq_len, ngram_seq_len, 10000, 256)\n",
    "oop_dataset = input_fn(oop_data_dir, word_seq_len, char_seq_len, ngram_seq_len, 10000, 256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list=[]\n",
    "label_list=[]\n",
    "source=[]\n",
    "for x in get_label_url_source(val_data_dir):\n",
    "    url_list.append(x[\"url\"].numpy().decode(\"utf-8\"))\n",
    "    label_list.append(np.argmax(x[\"label\"].numpy()))\n",
    "    source.append(x[\"urlSource\"].numpy().decode(\"utf-8\"))\n",
    "\n",
    "engineered_char = []\n",
    "engineered_ngram=[]\n",
    "engineered_word=[]\n",
    "for x,_ in input_small_fn(val_data_dir, 200, 200, 20, 15):\n",
    "    engineered_char.append(x[\"char_input\"].numpy())\n",
    "    engineered_word.append(x[\"word_input\"].numpy())\n",
    "    engineered_ngram.append(x[\"ngram_input\"].numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(engineered_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(path):\n",
    "    result={}\n",
    "    tmp = pd.read_parquet(path)\n",
    "    for token, index in zip(tmp.iloc[:,0], tmp.iloc[:,1]):\n",
    "        result[index]=token\n",
    "    return result    \n",
    "word_dict = make_dict(\"/home/youngjai/sampleData/ailab/workspace/youngjai_kwon/pml-data/engineered-data/totalSet/2020-11-09/small_dictionary/wordTokenIndex\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result2(model, engineered_char, engineered_ngram, engineered_word, url_list, label_list, target_label, idx_url):\n",
    "    \n",
    "    char_tensor = tf.convert_to_tensor(engineered_char)\n",
    "    ngram_tensor = tf.convert_to_tensor(engineered_ngram)\n",
    "    word_tensor = tf.convert_to_tensor(engineered_word)\n",
    "    \n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(\"word_layer_fsize_3\").output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape: \n",
    "        conv_outputs, predictions = grad_model([char_tensor, word_tensor, ngram_tensor])\n",
    "        loss = predictions[:, target_label]\n",
    "    grads = tape.gradient(loss,conv_outputs) \n",
    "    guided_grads = tf.cast(conv_outputs > 0, \"float32\") * tf.cast(grads > 0, \"float32\") * grads  # [10, 198, 256]\n",
    "    weight = tf.reduce_mean(guided_grads, axis=1)  # (10, 256)\n",
    "    \n",
    "    # conv_outputs : [10, 198, 256]  => [10, 256, 198]\n",
    "    # tf.stack([weight],axis=2) : [10, 256, 1]\n",
    "    # cam : [10, 198]\n",
    "    cam = tf.reduce_sum(tf.multiply(tf.transpose(conv_outputs, perm=[0,2,1]), tf.stack([weight],axis=2)),axis=1)\n",
    "    \n",
    "    tmp = tf.stack([tf.stack([cam], axis=2)], axis=3)\n",
    "    \n",
    "    # [10, 198]  => [10,198,1,1] 으로 바꿔줌. \n",
    "    tmp = tf.image.resize(tmp, size=[200,1])\n",
    "    answer = tf.squeeze(tmp, axis=[2,3]).numpy()\n",
    "    \n",
    "    print(url_list[idx_url], \"  :  \",label_list[idx_url] )\n",
    "    \n",
    "    for i in range(20):\n",
    "        idx2 = engineered_word[idx_url][i]\n",
    "        word = word_dict.get(idx2)\n",
    "        prob = answer[idx_url][i]\n",
    "        print(word,\" \",prob,\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://112.17.13.225/files/3069000004ADAFEC/down1.7654.com/n/tui/tpop/tpop3/v3.0.7.19/tpop3-8.exe   :   1\n",
      "http   5.537852e-05 \n",
      "\n",
      "files   3.522598e-05 \n",
      "\n",
      "<UNK>   3.470149e-05 \n",
      "\n",
      "down   3.780583e-05 \n",
      "\n",
      "com   1.9966545e-05 \n",
      "\n",
      "n   1.5988115e-05 \n",
      "\n",
      "tui   1.8339822e-05 \n",
      "\n",
      "tpop   6.041335e-06 \n",
      "\n",
      "tpop   8.285203e-06 \n",
      "\n",
      "v   2.6826136e-05 \n",
      "\n",
      "tpop   3.592126e-05 \n",
      "\n",
      "exe   2.1319136e-05 \n",
      "\n",
      "<PAD>   8.915838e-06 \n",
      "\n",
      "<PAD>   7.430641e-06 \n",
      "\n",
      "<PAD>   7.430641e-06 \n",
      "\n",
      "<PAD>   7.430641e-06 \n",
      "\n",
      "<PAD>   7.430641e-06 \n",
      "\n",
      "<PAD>   7.430641e-06 \n",
      "\n",
      "<PAD>   7.430641e-06 \n",
      "\n",
      "<PAD>   7.430641e-06 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_result2(model, engineered_char, engineered_ngram, engineered_word, url_list, label_list, 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
